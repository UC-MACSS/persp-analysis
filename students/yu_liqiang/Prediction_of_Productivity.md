## Prediction of the Productivity of Researchers Based on The Heterogeneity of Their Co-authors


### Introdution

The meauses of effectiveness of a research project are important for both academic institutions and funding resources to consider in allocating limited research resources and funding [[1]](http://www.the-scientist.com/?articles.view/articleNo/41682/title/Assessing-Research-Productivity/). Usually, productive and renowned researchers tend to receive more funding because of their reputation. So we are also curious to know if a researcher is productive, considering the limited scientific resourses and the existing tenure appointments in academia, although measuring faculty productivity is still a controversial policy [[2]](http://www.chronicle.com/article/How-Not-to-Measure-Faculty/130015). It is often the case that one receives the most citations in the middle of his academic career, leaving a difficult problem for fundations to assess his potential to conduct effective researches in one's early academic life. Here, we want to find a relation between the heterogeneity of one's co-authors, i.e., the variety of their backgrounds and the productivity of one, using observational data analysis. By knowing this relationship, research instituations and foundations are better on allocating research resources to potential researchers.

### Background and Significance

Unlike 50 years ago, today, scarcely do researchers mail their manuscript for publishing, rather, they submit through online system, such as [EviseÂ®](https://www.elsevier.com/authors-update/story/tutorials-and-resources/understanding-the-publishing-process) or [arXiv](https://arxiv.org/help/general). These online archive systems built for research articles provide enormous and analyzable data sets about academic research itself. This enable us to analyze research as a whole. For example, we can track the trend and the change of computer science research during the period 1995 - 2000 or map the relation of subfields in a specific discipline such as biophysics, biochemistry and bioinformation. This research of researches presents the potential of guiding researches, avoiding unnecessary fundings and evaluating researchers.

We will propose and test a hypothesis that the productivity of a researcher is positively affected by the heterogeneity of his co-authors and use this result to 'nowcast' his current productivity, due to the lag between a publication and its citations. This prediction, not only will give advice to young researchers on how to conduct valuable researches, but also is a guidance for academic institutions and foundations to select potential researchers and provide solid support to them. 

To approach this problem, we set Google Scholar as our data source. Google Scholar possess many good characteristics for our analysis. First, Google Scholar has a board coverage of English publications with an estimate of 80% - 90% of all English publications, which includes many observations, a number of researchers and lots of information about publications per person, enabling academic heterogeneity for a better understanding [[3]](http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0093949). Further more, this amount of data even allows us to estimate a specific group, e.g., the subfields of economics, such as econometrics or behavior economics under economics. Second, it is always-on. A scholar's articles are set default to be updated automatically whenever Google Scholar is updated [[4]](https://scholar.google.com/intl/en/scholar/citations.html#updates). Finally, the database is non-reactive, which avoids behavior change when we conduct our research. 

However, the data itself has weakness. Foremost, some scholars do not use Google Scholar and they tend to use their own website, resulting the data for some objects is incomplete so we cannot get the information directly, especially when we want the backgrounds of co-authors. And users' behavior of Google Scholar can be drifting. There exists the probability that one is more likely to cooperate with 
others from different backgrounds today than in 2004, when Google Scholar just launched and provided a good platform for sharing ideas and cooperating.

Besides data resources, it is necessary for us to define how to measure the productivity of a researcher and the heterogeneity of his co-authors. Although there is already a method to measure one's productivity called h-index [[5]](https://en.wikipedia.org/wiki/H-index), there is not such a well-accepted way to measure the heterogeneity of a scientist. 

So in our research, we will first define the measure of productivity of one and the heterogeneity of one's co-authors. Then we randomly pick a set of scholars from different disciplines and make sure that their age and research fields are uniformly distributed on a spectrum. Noticing that in different disciplines or different age groups, the average h-index can be different, we will construct a matching process for fair comparisons.

###Research Design and Methods

In the beginning stage, we will collect the data from Google Scholar. Before collecting, we define the productivity of a researcher as the value of his h-index on his profile page on Google Scholar, which is a well-accepted measure of productivity among academia. And we define the heterogeneity of his co-authors simply by counting the number of different fields or subfields from which his co-authors come minus the number of his research fields. For example, in a researcher's profile page ([Melanie Swan](https://scholar.google.com/citations?user=3Jar2L8AAAAJ&hl=en&oi=sra)) on Google Scholar, we can get one's number of research fields (philosophy, economic theory, complexity, genomics, blockchain technology, so the number is 5 in this case) and a h-index of 13 for her. Then we select 10 fields such as 
[statistics](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Astatistics&btnG=), 
[economics](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Aeconomics&btnG=), etc., and randomly pick researchers from the [list](https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=label%3Aphysics&btnG=) to collect information about their h-index and co-authors of their papers. Later on, we calculate the heterogeneity of his co-authors. It is where we may encounter incomplete data of co-authors so we have to manipulate missing data by methods introduced in [Statistical Analysis with Missing Data](https://books.google.com/books?hl=en&lr=&id=AyVeBAAAQBAJ&oi=fnd&pg=PT8&dq=missing+data&ots=uyP03xkRhz&sig=7_XA4j9S85dic21b0ei4ugdv0Lk#v=onepage&q=missing%20data&f=false). 

In the second stage, as we mentioned above, the measure of productivity, i.e. h-index varies among different age groups and different fields. Thus, matching is necessary to obtain fair comparsions in this case. Also, to some degree, matching helps us alleviate or even eliminate the influence of population drift, under the assumption that we assume people in the same age group have similar habits of using Google Scholar. If we take it as a natural experiment here, it may result in wrong conclusion, since it ignores the fact that the number of participants in specific field and differences in age groups both have influence on h-index calculation. After matching, for each group, a simple x-y plot with x-axis representing heterogeneity and y-axis indicating productivity can give us an intuitive impression about the relationship of these two indicators. Additionally, we further apply a linear regression model to acquire its  mathematical expression.

In the final stage, we can 'nowcast' the productivity of one because there always exists a lag between a publication and its most citations (h-index), which usually takes years. We are able to immediately obtain the 'real' h-index of one, which provides guidance for academic institutions and foundations in allocating limited research resources. Here, a forecasting is unnecessary, since there are many other factors that can impact h-index, such as the trend of one research field, the amount of funding and the number of incoming talents. 

###Conclusion

This research could shed light on the path where researchers are struggling to improve their productivity and give a guidance for academic institutions or foundations to fund promising young researchers by answering the question about the relationship between the heterogeneity of one's co-authors and his productivity. We choose to do matching and nowcasting in our research because of the variety among different age groups and disciplines and the underlying complexity for forecasting. Moreover, this study implicate that we could extract more information about research as whole by doing researches of research. And my former study in statistics and programming enable me to conduct this study prperly.

