###Final Exam
by Sumer S. Vaid 


**Summarize the research design and explain how the research design leverages computational methods to ask and answer a question.**

**Edelman and Luca (2014): **

-Summarize the research design:

This is an observational study in which the authors use existing datasets from Airbnb to examine how racial discrimination manifests in digital marketplaces. Their measure of racial discrimination (dependent variable) is the amount of rent money that African American individuals receive in comparison the rent money that Caucasian individuals receive when controlled for all those non-racial factors that influence rent. There are two types of non-racial factors that influence rent payment: those designed by Airbnb (i.e location, social network presence of host) and those factors that are unintendedly contributing to increasing in rent payments. The authors attempt to control for all non-racial factors influencing this difference in rent paid, including factors like location, reviews, and photos. Specifically, by algorithmic design, the price of an Airbnb listing increases with the number of guests to be accommodated, the location rating of the Airbnb, and the social network presence of the host. In their analysis, the authors attempt to also control for all of these factors so they can directly examine the isolated impact of race on rent-payments. Demand for property is not accounted for rent payments in the house. 


-Explain how the research design leverages computational methods to ask a question.

This research study examines data generated on a digital platform to answer a question related specifically to digital platforms. Specifically, the authors are interested in examining if discrimination arises as an unintended consequence of linking personal profiles to digital marketplaces like Airbnb. While this detailed personal information serves to build trust between renters and tenants, this personal information can also cause discrimination amongst renters and tenants. Hence, computational and digital methods are leveraged to answer questions unique to digital marketplaces: the authors use digital methods to ask how racial discrimination manifests in Airbnb. Because of the computational methods they deploy, the researchers are able to get specifically at their intended isolated effect of race on rent payments. This would not be possible in a non-computational methods study, as it would be impossible to control for non-racial factors influencing the asking rent of properties. This is easy to do in a digital methods study as renters present themselves in a structured and constant way (because of AirBnB's requirements), because all tenants have access to the same information and because the exact dollar amount of rent is known. Hence, the authors utilize computational methods to ask a uniquely specific question pertaining to discrimination in marketplaces. This type of a unique question will be difficult, if not impossible, to ask in a non-computational methods study. 


-Explain how the research design leverages computational methods to answer a question. 

1) Human computing/mass collaboration is used to code the race of Airbnb Hosts, which is a uniquely computational research method. The reliance on many numerous Mturk workers as opposed to a small pool of research assistants vastly increases the external validity of the race determination of Airbnb hosts.

2) Human computing/mass collaboration is used to code the attractiveness of an apartment listing, which is a uniquely computational research method. The reliance on many numerous Mturk workers, many of whom have used Airbnb in the past and will use AirBnB in the future, increases the external validity of these apartment ratings. 

3) All the data that the authors analyze originates from Airbnb, and this reliance on computational methods allow the researchers to answer how racial discrimination manifests on Airbnb. Computational social science methods are deployed in scraping this data using APIs and browser tools. 

4) The methods of data analysis that the researchers employ are heavily computational in nature. The computational methods that the researcher's leverage, especially in modeling the contributions of various non-racial factors on rent paid, allows the researchers to answer their research question of how race specifically influences rent paid, as opposed to these extraneous factors. This would not be possible in a non-computation analysis, as factors influencing rent paid would be impossible to factor out without careful implementation of computational methods. 

**Edelman, Luca and Svirsky (2017): **

-Summarize the research design 

This study employs a combination of an experimental design, an observational design, and a survey design. The design of the study is further aided by human computation, as MTurkers (three) are employed to classify the race, gender, and age of hosts based on their pictures. 

The survey component of the survey is employed to validate the race-signaling nature of various names, borrowed from an earlier study. In this component, a group of subjects is required to categorize the race of a name within 3 seconds. The independent variable is the name observed by participants. The dependent variable is the race-categorization of the name made by the participants. 

The experimental component of the researchers employed a 2 (race) x 2 (gender) between-subjects design. Hence, hosts were contacted from one of four accounts: white male, white female, African-American male and African-American female. There were five accounts per each of these four treatment group accounts. The dependent variables were the classification of responses sent back to these accounts from contacted hosts, as tracked over a 30-day period. These responses were classified into one of six categories: No response, No/Unavailable, Yes with follow-up questions, check back later for the final answer and will revert later. 




-Explain how the research design leverages computational methods to ask a question.

The authors' questions specifically require the leveraging of computational methods to be answered effectively. The authors seek to experimentally determine how one's racial background, as indicated by their name, impacts their odds of receiving a positive reply from hosts. Computational methods are leveraged in asking such a question because, without digitally-obtained data, an organized intervention of this kind could not be staged. Second, without computational methods, the researchers would not be able to statistically assess the impact of their interventions on renting behavior, due to the various confounds between listings, rent paid and host/tenant traits. Third, without computational/digital methods, the hosts could not be categorized on a plethora of personal traits as they were in the present study. This would prevent the researchers from asking questions about *how* hosts from a variety of racial and socio-demographic backgrounds responded to queries from guests of varying racial backgrounds. 

-Explain how the research design leverages computational methods to answer a question. 

1) Human computing is used to code a variety of features relating to the background of the Airbnb hosts, which is a central method in computational and digital methods. Computational social science methods are deployed in scraping relevant data using APIs and browser tools. Digital methods are deployed in creating bot accounts on AirBnB to query different hosts about room availability. Additionally, the Face ++ API is used to classify past guests by variety of measures such as race, gender, and age. This is a unique computation research method.

2) The experiment is a "digitally-enriched experiment": the interventions staged, the data collected, the dependent variables examined and the environment controlled are all done on the internet. As the researchers' specific question concerns racism expressed on AirBnB, their research questions would be impossible to answer without the aid of digital methods. 

3) The methods of data analysis that the researchers employ is heavily computational in nature. The researchers construct a variety of models to explain variation in renting behavior as a result of different psycho-demographic traits of hosts and the race of tenants. This type of analysis would not have been possible without (a) a digitally-enriched experiment and (b) computational methods of analysis. Hence, the researcher's answering of their question is also heavily dependent on the computational nature of their experiment.


**Evaluate the effectiveness of each paper's research design independently. That is to say, what do we learn from each paper on its own? What are the limitations of each paper on its own? Think back to Salganik's characteristics of big data and our assessment of experiments' validity, heterogeneity of treatment effects, and causal mechanisms. Draw on these methods of assessment as you evaluate the effectiveness of each paper.**

**Edelman and Luca (2014): **

-What do we learn from each paper on its own? 

This paper finds that when controlling for all non-racial factors influencing rent, non-black hosts make 12% more for congruent apartments with a similar rating distribution and photo presentation relative to black hosts. The researchers are unable to disentangle the contribution of two forms of discrimination on overall discrimination observed: statistical discrimination and taste-based discrimination. Lastly, the results of the authors hold even when specifically rent payments to whites are compared with blacks.

This paper uses an observational study to examine how racism manifests itself on rent paid to African American vs non-African American landlords after controlling for all other factors that influence rent payment. This research design is advantageous because people have not reacted to researcher measurement, and therefore have been observed in their comfort zone on social media environment. This boosts the external validity of the results that the researchers obtain. Moreover, the researchers examine "big data" - this data contains a lot of information from a lot of people, which can allow for the detection of relatively small and subtle effect sizes. Moreover, this large number of observations reduces the probability of selective sampling or biases introduced by sampling a small group of individuals not representative of all Airbnb users. 

The authors' statistical validity is particularly high in this research as they employ a rich mix of models that allow them to get at their isolated, intended effect with a reasonable amount of certainty. 

-What are the limitations of each paper on its own?

However, this comes at the cost of internal validity of their research: the operationalization of the construct of digital racism cannot be disentangled from demand-based fluctuations in property prices. This is a key driver of prices in the sharing economy, and this is a significant weakness of this paper. It can be, for instance, that white-landlord properties are simply more in demand than non-white properties, because of reasons that are not directly linked to racism and prejudice. Moreover, guests' concerns about the nature of black properties in general - such as their location in unsafe neighborhoods - is acknowledged but ignored by the authors on the basis of their results being robust to attributes readily available in apartment listings on Airbnb. This further reduces the construct validity of this research, as all non-racial factors driving the difference in rent payments cannot be factored out of the authors' analysis. Lastly, the causal impact of landlord race on rent paid cannot be directly examined as this is not an experimental study. 

Second, we know that Airbnb refused to collaborate with the researchers on this study. Hence, potential effects originating from algorithmic confounding cannot be removed from the analysis of observed effects. AirBnB's lack of cooperation further introduces the possibility of system drift confounding the observed results of the author. While it is unlikely that the Airbnb implemented major system changes on the same day that the authors choose to snapshot their listing data from, note that the characteristics of the host and the apartment may have been created over varying time frames prior to the snapshot day. This can introduce bias in the results because of system drift. 

Third, it is clear that the data being handled by the authors is extremely sensitive in nature. This introduces a significant privacy concern into the authors work: all steps required to reproduce the authors' analysis is reliant on the sharing of this sensitive information, including highly sensitive photos of the apartments, the tenants, and the landlords. This reduces the ease with which the author's analysis can be replicated and therefore affects the transparency of their work. 

Fourth, the ethical nature of this study is dubious. As participants did not consent to participate in the experiment, and troves of their personal data were analyzed in the process, the study borders on violating a researcher's code of ethics. While this does not impact the design of the study in any way or influences its results, ethicality of research is an important component in evaluating the research design. Under the principle of beneficence, this research ultimately seeks to reduce discrimination by using data that is publicly available. However note that the participants have made their data available to the public because of a monetary incentive (i.e rent paid) or in the case of tenants, a convenience incentive (i.e finding a place to stay). The researchers use their data for reasons other than these and hence violate their privacy. Regardless of whatever benefits maybe conferred from this study, I believe this violates the ethicality of the research. 

**Edelman, Luca and Svirsky (2017): **

-What do we learn from each paper on its own? 

The authors find that queries about Airbnb properties are 16% less likely to be accepted when sent by guests with distinctively African American names relative to identical guests who have easily recognizable white names. The authors find that this type of discrimination occurs amongst landlords renting out apartments of all sizes, including shared apartment landlords and landlords with numerous properties listed. The authors further find that the effect is accentuated for hosts who have never had an African American guest. The authors assess the external validity of their research by examining how hosts that have already hosted African Americans in the past predicts the likelihood of a host responding positively to the inquiry as a function of the race of the guest. The authors find that the gap in race-based responses drops significantly amongst hosts who have at least one recent testimonial from an African American guest. 


-What are the limitations of each paper on its own?

Internal Validity and Construct Validity

The internal validity of this research is fairly high because randomization is deployed effectively to avoid introduction of systematic bias. The authors verify that their independent variable (name-race signaling) is operationalized well through a survey verification consisting of responses from the same type of people that would be hosts and guests on Airbnb. The authors don't attempt to pre-classify all responses received to their inquiries, but instead, do this after all the responses have been received. This allows them to capture and examine the diversity of responses extremely well, without introducing biases into the classification prior to responses received. The biggest limitation of the study is that the effect of race on rent paid cannot be disentangled from a host of psychosocial, socioeconomic and demographic traits of the users. That is, among other factors, the race of the participants might be used by hosts to infer a variety of non-racial traits of the guests which might be driving their response-based decision as opposed to the race of the participants specifically. Second, it remains unclear if the manipulation is having the intended effect. If the authors had somehow manipulated the hosts into revealing the race they were assigned to the name of the participants they were reading, then this would have served as a good manipulation check. In its present state, the possibility remains open that the hosts inferred non-racial traits from the names of interested tenants, and used these factors to make their decisions. This is a type 2 error. 



External Validity

The external validity of this research is fairly high as the researchers supplement their experimental findings with an observational examination into which hosts are more or less likely to discriminate against African-American guests. The authors utilize the "always -on" characteristic of big data to examine the tenant history of landlords so they can propagate claims about which hosts are more or less likely to discriminate. The external validity of this research does suffer from the fact that in general, neither of the tenant accounts contain photos. Though this doesn't affect the internal validity of the researcher's findings (because all treatment groups contain no photos), it does reduce the generalizability of the authors' findings to accounts with photos and other information. Second, the external validity of the research suffers from a chosen time frame of 8 weeks into the future. Once again this choice of time frame does not impact the internal validity of the research, but it does reduce the generalizability of the authors' findings. For instance, it remains unknown if the "race gap" originates only in instances where African-American tenants without profile pictures inquire about a listing 8 weeks into the future, or if this effect can be generalized across the board. Some of these concerns are alleviated with the supplementing of the experimental work with observational data: the fact that the race gap disappears among hosts who have accommodated African American guests in the past implies that the findings from the experiment do not result from any specific relic unique to the experiment. 



Statistical Validity

The authors deploy a variety of regression models to get at their intended effect. They routinely list the significance level they are using to determine the significance of their obtained results. The authors, therefore, ensure that their work has high statistical validity. 

Heterogeneity of Treatment Effects and Causal Relations

The large amount of data stored on AirBnB allows the authors to examine the heterogeneity of treatment effects. The authors first break-down their subject sample (tenants) into racial sub-groups to examine if the driver of the race gap effect is simply a preference for in-group members as opposed to an overt preference for white tenants. Hence the authors test the prediction that African American guests face higher acceptance rates from African American hosts. The authors are able to further examine the heterogeneity of treatment effects within these racial groups, by examining gender by race interactions between hosts and tenants. The noisiness of the point-estimate prevents them from generating conclusive results about homophily, but their data allows them to at least examine the heterogeneity of treatment effect. The authors then examine the heterogeneity of treatment effects by examining how discrimination is influenced by a host's proximity to the guest during the time of stay. The authors classify all properties as either shared or not shared and find that the race gap is robust across these tenant sub-groups. The authors then break-down the tenants into a different sub-group: those that are professional Airbnb users and those that are not professional Airbnb users. They do this by creating tenant subgroups based on hosts who offer multiple properties and those that have more than ten reviews. The experimental intervention does not result in varying results over these subgroups, suggesting that the race gap is robust to professional as well as novice renters. Importantly, not only does the race gap persist in these heterogeneous treatment groups, but it persists with similar magnitudes. Finally, the authors employ Mturk workers to categorize hosts into subgroups of young, middle-aged or old. The authors find that discrimination persists across these age categories with the same magnitude. The authors also break-down the listing owned by various tenants into different subgroups based on listing characteristics. Discrimination remains robust for both - more expensive and less expensive listings. The authors also break-down the listings by their desirability - by checking whether the listing was eventually filled for the nights targeted in the experiment. The authors build a model to predict the likelihood that the listing was filled controlling for cities and plethora of other covarying factors. Using this model, the authors find that the desirability of the properties does not influence discrimination. The authors further break-down the listings as a function of neighboring diversity. They find that even this subgrouping does not influence discrimination against potential tenants. Overall, the robustness of the author's central findings across an examination of varying subgroups significantly strengthens the external and internal validity of their main finding. In other words, the lack of heterogeneous effects observed across treatment groups supports the robustness of the researcher's findings of the race gap. 

**Identify the value-added of conducting both research projects. That is, what do we learn from running both an observational study and a field experiment that we could not learn from just one of these methods?**

Combined, the two research projects present robust findings that have both high internal and external validity and are less likely to be biased by some of the negatives of big data research like system drift and algorithmic confounding. In the observation study, researchers are able to examine Airbnb users in their natural habitat without intervening with their behavior. This is especially important in the context of discrimination because social norms would lead to immediate change in discrimination behavior if participants find they are either being examined or experimented with. This boosts the external validity of this observational research, though it raises ethical concerns of handling extremely sensitive data without the permission of either Airbnb or the guests in question. The biggest weakness of the observational study is its inability to examine the demand component of price variations, and its inability to factor this out of the rent gap observed. The experimental study focuses on carefully assessing the demand features of the Airbnb market, and the researchers are able to show a robust race gap that persists across treatment of various sub-groups of the subjects. The experimental nature of this study allows the researchers to validate causal claims about exactly *what* drives host decisions about whether or not to rent apartments to individuals with a certain racial and gender-based background. The two studies are different in that the observational study seeks to understand how landlords are discriminated against by hosts whereas the field experiment seeks to understand how landlords discriminate against hosts. Hence, in concert, these studies allow us to understand how discrimination operates in a two-way stream on the Airbnb marketplace while boosting the external and internal validity of findings crystallized by each of these studies. 

The field experiment understandably relies on a smaller dataset to infer causality because of practical and monetary conditions. The observational experiment is able to sample large data-sets and offer more general claims about how landlord-based discrimination operates. 

The field experiment is ethically dubious as well, perhaps more so than the observational study, as experimenters are deceiving the hosts with potential losses including monetary attrition that can have negative consequences for the well-being of the participants. Both the observational study and the field experiment are likely illegal given Airbnb's terms of service, and therefore the researchers violate several ethical norms related to sound scientific research. 

In summary, the observational study offers insight into how discrimination channels from tenants towards landlords. This study offers high external validity, is able to measure relatively small effect sizes robustly, and is able to observe the behavior of the participants without intervention. The experimental study offers insight into how discrimination channels from landlords towards tenants. This study offers high internal validity, is able to propagate causal claims about how race influences renting behavior but does with a smaller dataset than the observational study. Taken together, these studies supplement each other in important ways: the "package" of these studies is scientifically more valuable than either isolated study. 

**Consider how you could apply a digital survey-based research design to the primary question of interest from these two papers. What are the potential drawbacks to a survey approach? How might you overcome these drawbacks?**

*Survey Design*

I would apply a digital survey-based research design to understand the strength of discrimination in individual interactions between hosts and guests, using monetary loss as a measure of understanding how aversive hosts are to renting out apartments to members of certain racial groups. My survey will "pop-up" after landlords send a negative reply to tenants' inquiries. The survey will consist of three questions, each appearing on subsequent, irreversible pages: (1) In the space below, describe your reasons for rejecting the request of this host. (2) If the host is willing to pay (a) 20% more than the asking rent (b) 50% more than the asking rent and (c) 100% more than the asking rent, will you reconsider? (3) List a new rent amount that will definitely incentivize you to reconsider your initial response. This survey will be administered each time a landlord rejects a tenant inquiry. I will attempt to compare the difference between the landlord's standard asking rent and their revised rent for approving certain tenants as a measure of how strongly they discriminate against that individual. Moreover, the purpose the survey will be deceptively advertised as means of developing a "surge" algorithm similar to that of ride-sharing companies. Landlords will be told that by answering this survey, Airbnb will ultimately be able to offer greater financial incentives to them. 

*Drawbacks*

The potential drawback to this survey approach is that Airbnb would likely not agree to have it instated into their features. This is because this survey reduces the user experience asymmetrically for hosts as compared to tenants, and might cause the hosts to stop using the platform because of cumulative time lost over repeated answers to the survey. 

Secondly, the strength of discrimination evidenced by this survey remains entangled with non-racial discrimination. For instance, tenants might report that they are okay with renting their apartment at higher prices because they are motivated to do so for reasons other than their discomfort with the race of the participants. 

Lastly, my survey asymmetrically assesses the bias of poorer hosts. That is, my survey assumes that all prejudiced hosts will serve to counteract their prejudice by asking for a higher rent. However, this is not true for wealthy and prejudiced individuals. These individuals will typically never agree to host African Americans, regardless of rent offered. 

*Overcoming Drawbacks*


 I believe that Airbnb has significant brand equity at stake if the mainstream media picks up on how insidiously racism is operating on the platform. 
 
 Instating this survey will serve to accomplish two related purposes. First, as the survey is administered immediately after the landlords reject tenants, the monetary questions will prompt landlords to think carefully about why they are rejecting these tenants, to begin with. While tenants may be biased against African Americans because of popular culture, this survey will prompt them to think carefully about the ethicality of their behavior as an overt thinking exercise. It is likely that many tenants reject African-American tenants without second thoughts, but would likely reconsider their decision after careful thought and introspection about their own inherent racism.  Second, this type of survey will allow Airbnb to quantitatively assess the topology of discrimination that a host practices against tenants of varying racial backgrounds. Over the long run, responses to this survey will help Airbnb build a measure of discrimination into host reputation, and will even allow the company to prompt hosts to either reduce their discriminatory behavior or permanently bar them from the platform. Under the deceptive mask of financial incentives, Airbnb will be able to measure and extract racial bias in its marketplace. 
 
Second, the design of my survey will us to selectively analyze the results generated by individuals who have already displayed race-based discriminator behavior on the platform. For instance, using methodologies employed by Edelman, Luca, and Svirsky (2017), I will first identify which hosts have already displayed racism. Then, I will only analyze survey results from these individuals to determine strength of discrimination, and identify property attributes and non-racial factors driving variations in strength of individual interaction discrimination. This analysis will help circumvent concerns about confounding racial discrimination with non-racial discrimination. 

Third, utilizing the digital footprints and social network presence of Airbnb hosts, I will classify them by socioeconomic status. These traits have been previously shown to be predictable from digital media footprints (for instance, see Preotiuc-Pietro et al., 2015). Having done so, I will then analyze the results of the survey by introducing the socioeconomic status as a quasi-variable in my regression models by analyzing the link between rent surplus and race of tenants making inquiries. This will allow me to factor in the socioeconomic status of the hosts in their responses of surplus rent, and therefore increase the robustness of my results. Additionally, I can also use this metric to exclude rich participants from my analysis. 

Collectively, my analysis methods and my research design will allow me to overcome most of the major drawbacks of my survey. In addition to helping Airbnb improve its marketplace, my survey will offer the first direct examination of the strength of race-based discrimination effects, which have long been an eluding object of study in prejudice psychology. This research will inform mechanistic claims about how race-based discrimination varies across interactions, and therefore lay the foundations for future interventions that can be deployed to reduce racial harrassment across interactions with varying levels of racism. Instead of the current approach in reducing racism, which assumes that all prejudiced relationships are equally racist, my research will allow us to develop customized interventions that are able to neutralize discriminatory behavior of varying levels. 


External Citations

Preo≈£iuc-Pietro, D., Volkova, S., Lampos, V., Bachrach, Y., & Aletras, N. (2015). Studying user income through language, behavior and affect in social media. PloS one, 10(9), e0138717.
