Soo Wan Kim  
MACS 30000  
Short Paper 1

#Ethics of "Taste, Ties, and Time"

In chapter six of *Bit by Bit*, Matthew Salganik lays out four principles of ethical research to guide social research in the digital age. This short paper applies those four principles to evaluate the ethics of a controversial study, “Taste, Ties, and Time” (Lewis et al. 2008).

##The Study

“Taste, Times, and Time” (T3) analyzes the relationships between social ties and various factors, including cultural tastes, over time. Beginning in 2006, Lewis et al. (2008) collected housing information on 1640 college students and linked it with data from their Facebook profiles to create an original longitudinal dataset containing various measures on their social relationships on Facebook as well as demographic and other information. Along with their findings and methods, the authors of T3 also released the dataset to the public after taking steps to ensure the students’ privacy. However, concerns over the ethics of the study and the dataset quickly arose, and the dataset was eventually redacted.

##The Four Principles
####Respect for Persons

Salganik defines the essence of this principle as “treating people as autonomous and honoring their wishes.” He suggests that this encompasses both the necessity of respecting individuals’ autonomy and that of providing additional protections for “individuals with diminished autonomy,” such as minors (Belmont Report 1979). 

In practice, this translates to obtaining informed consent from the research subjects themselves whenever possible. The authors of T3 obtained permission from both Facebook and the university to collect and use the students’ data for their study; however, they did not seek consent from the students in question, nor did they inform the students of the proceedings. In this sense, T3 fails to adhere to the principle of Respect for Persons.

One could still argue that, since the Facebook profile data was technically public, the students had implicitly consented to the use of the information for research purposes. Moreover, they had all agreed to Facebook’s Terms of Services, which grant Facebook the right to authorize studies on the data. 

Such an argument does not resolve the issue of violation of privacy, or the broader issue of honoring people’s wishes regarding information flow. As Salganik argues in section 6.3 of chapter six, privacy ought not to be viewed in terms of a simple public/private dichotomy, but rather in terms of context-relative informational norms. In other words, the fact that the data was readily available to anyone who searched for it does not make it non-private from the perspective of the students, as the context of providing personal information for networking and social purposes differs from that of allowing researchers to use and release that information in a public dataset. Thus, due to the failure to obtain informed consent, the study does not respect the participants’ autonomy.  

Regarding the issue of additional protections for individuals with diminished autonomy, Lewis et al. were unclear as to whether the study included any students who may have benefited from additional safeguards, such as minors. Some of the participants may have been under 18 at the time of the study; however, as college students most of the students would have been 18 or older.
 
In addition, the fact that the students agreed to Facebook’s Terms of Service does not necessarily grant ethical clearance to use their data without their explicit consent. As Salganik states, “the basic idea with informed consent is that participants should be presented with relevant information in a comprehensible format and then should voluntarily agree to participate.” The Facebook Terms of Service is unlikely to have said anything specifically about the use of user data for the T3 study, the relevant information in this case, and also unlikely to have been presented in a “comprehensible format.”

####Beneficence

“Beneficence is about understanding and improving the risk/benefit profile of your study, and then deciding if it strikes the right balance.” (Salganik 2017)

At first glance, the potential risks of the study and the associated data, as published, appear few and small, while the potential benefits seem many and great. As one of few studies at the time that exploited the potential of social networking sites, it possessed unusual advantages. For example, Lewis et al. compiled data on a wide range of categories of interest to researchers, including the students’ demographic information, socioeconomic status, living arrangements, relationships on Facebook and on campus, major, cultural tastes, sexual interests, and political views, among others (Lewis 2008; Zimmer 2010). In addition, they were able to collect “naturally occurring” data without they or their assistants directly intervening in the processes involved. Moreover, they could easily track the same population over time, allowing for a longitudinal study. 

Thus, the dataset contained many characteristics that made it useful for additional, varied research projects on topics such as racial and cultural homogeneity in social networks (Lewis et al. 2011; Wimmer & Lewis, 2010). Keeping the data open access and adding to it over time, as the authors intended, would likely have fostered even more studies and provided an additional boon to public knowledge.

Possible risks to participants appear not to have been major; at least, no harm was clearly done. Lewis et al. also took the step of anonymizing the data to protect the students’ privacy and reduce informational risks. They claimed to have removed all personally identifying information from the data. In their own words, “student privacy was assured” (2008). In addition, researchers wishing to use the data were required to agree to a “terms and conditions for use,” among other safeguards (Zimmer 2010). 

At the same time, Lewis et al. clearly misunderstood and miscalculated the possible range and severity of risks. As noted by Zimmer, the attempts to anonymize the data failed in multiple ways. For instance, although access to the data was conditioned on accepting the terms of use, access to the codebook was not, and multiple individuals were able to identify the “anonymous” college from which the study was conducted (Harvard College) as well as several individual participants using just the codebook and the published study (Zimmer 2010; Parry 2011). 

In hindsight, the attempts to cloak the identity of the school appear extremely careless, even pointless. Four of the researchers were based in Harvard, the study explicitly described the school as private and located in the Northeast US, and the codebook gave away the approximate student population, demographics, and even names of majors uniquely offered at Harvard (Zimmer 2010).

Even more concerning, it was possible for outsiders to track down individual participants without even accessing the dataset. The codebook listed national and geographic origins for all the students, and because some categories included only a few students, it was easy to identify the individuals from information available elsewhere. One reporter was able to identify and contact one of the students from the study, one of the three students from Utah (Zimmer 2010; Parry 2011). In addition, the dataset contained potentially sensitive and risky information, such as those regarding political views and sexual interests.

Lastly, according to several sources Harvard students had been employed in the study to collect the Facebook data (Zimmer 2010; Kaiser 2011; Parry 2011). While T3’s authors intended only to use public data accessible to individuals not affiliated with the participants, the fact that fellow Harvard students collected the data makes it likely that the finished dataset contained at least some private data meant only for Facebook friends. The principal investigators did not set guidelines as to whether or not the RAs could collect this private or in-network-only information for the purpose of the study, nor did they check to make sure that no private information was collected. 

Thus, it appears Lewis et al. miscalculated the risks of the study in terms of the potential to accidentally release sensitive data. On the other hand, because the academic benefits of the data are so great, it is difficult to conclude that the costs outweigh the benefits. 

####Justice

“Justice is about ensuring that the risks and benefits of research are distributed fairly” (Salganik 2017). 

In practice, this can be interpreted to mean (1) that vulnerable groups should be protected from exploitation by researchers and (2) that the study should preferably include diverse subsets of the population as participants. 

The participants of T3, being students at a prestigious university, form a particularly privileged subset of the population. Thus, they are not a particularly vulnerable group. The participant pool was arguably diverse in terms of racial, ethnic, socioeconomic, and geographical background; on the other hand, again, they still represent a very narrow subset of the population for the reason given above. 

Lastly, Salganik points out that the students were not compensated financially for the use of their information and that they effectively bore the burdens of research themselves while society as a whole benefited; however, one could also argue that they benefited from the findings of the study as well, and possibly particularly so in some cases because they had a personal connection to the data.

As a whole, the study cannot be said to *not* adhere to the principle of Justice, though it does deviate from the ideal in some ways. 

####Respect for Law and Public Interest

“Respect for Law and Public Interest extends the principle of Beneficence beyond specific research participants to include all relevant stakeholders” (Salganik 2017).

Specifically, as argued in the Menlo Report, researchers must comply to laws and regulations and also be transparent about the “goals, methods, and results” of their study.

The T3 study is not known to have broken any laws, nor was it flagged for violating research regulations or relevant terms of service. Both the Harvard IRB and Facebook approved the study. In addition, Lewis et al. disclosed the contents of their study clearly and transparently in the article, which was published in an academic journal. Thus, the study meets the standards of Respect for Law and Public Interest.

One potential problem is the previously mentioned issue of having used Harvard students to collect Facebook data on fellow students. Although Lewis et al. intended to use only data available to the public, it is not clear whether they actually did so. Even the accidental use of private data in this context could potentially cause legal repercussions, as one of the authors admits: Jason Kaufman states in an interview that the issue of the assistants introduces "an interesting wrinkle… from a legal point of view" (Parry 2011). 

##Closing Remarks

In light of the potential and apparent ethical issues enumerated above, I would prefer not to use the T3 data (if made available) for my own research. While I am not particularly concerned about any actual risks from the dataset to the participants, I believe the lack of concern shown for the autonomy of the participants and the inadequate safeguards in place to protect their privacy set an unfortunate example for future research. Furthermore, these factors are likely to color research arising from this data in a negative light in the public perception, which may have any number of chilling effects, as well as negatively impact my career should I choose to use the data. 

However, if these concerns could be mitigated with extra safeguards, such as stronger anonymization measures and limits on who has access, the dataset may be a sufficiently attractive resource even without seeking (much belated) informed consent from the original participants. Finally, the data should be submitted for review with the relevant regulatory bodies to ensure that it adheres to all laws and regulations.

##References
Lewis, Kevin, Jason Kaufman, Marco Gonzalez, Andreas Wimmer, and Nicholas Christakis. "Tastes, Ties, and Time: A New Social Network Dataset Using Facebook.com." *Social Networks* 30, no. 4 (2008): 330-42.

Lewis, K., M. Gonzalez, and J. Kaufman. "Social Selection and Peer Influence in an Online Social Network." *Proceedings of the National Academy of Sciences* 109, no. 1 (2011): 68-72. 

Wimmer, Andreas, and Kevin Lewis. "Beyond and Below Racial Homophily: ERG Models of a Friendship Network Documented on Facebook." *American Journal of Sociology* 116, no. 2 (2010): 583-642.

Zimmer, Michael. "But the Data Is Already Public”: On the Ethics of Research in Facebook." *Ethics and Information Technology* 12, no. 4 (2010): 313-25.

Kaiser, Tiffany. "Harvard Sociologists in Hot Water Over Facebook Study; Student Privacy Called into Question." DailyTech. July 11, 2011. Accessed October 9, 2016. http://www.dailytech.com/Harvard+Sociologists+in+Hot+Water+Over+Facebook+Study+Student+Privacy+Called+into+Question/article22116.htm.

Parry, Marc. "Harvard Researchers Accused of Breaching Students' Privacy." The Chronicle of Higher Education. July 10, 2011. Accessed October 9, 2016. http://www.chronicle.com/article/Harvards-Privacy-Meltdown/128166/.

Salganik, Matthew J. 2017. *Bit by Bit: Social Research in the Digital Age*. Princeton, NJ: Princeton University Press. Open review edition.
