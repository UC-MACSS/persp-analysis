# Final Exam         


## The First Paper      
### Research Design

Using an observational data set and other existing information, the researchers in this paper explored racial discrimination against landlords/hosts on Airbnb. Specifically, they investigated and estimated the price gaps between black and non-black hosts by controlling non-race variables, and thereby evaluated the racial discrimination on Airbnb.

- They first collected the data set consisting of a snapshot of listings from Airbnb for New York City as of July 17, 2012. Furthermore, they collected the useful information from these listings, including the price asked by the host, the characteristics of host, the characteristics of the apartment, the number of review left by guests, a set of average ratings evaluating several dimensions of the host.    

- They hired workers on Amazon Mechanical Turk to identify the photo in each listings. The workers were told to rate the quality of the apartment in photos on seven-point scale ranging from bad to good quality.      

- In order to obtain the racial information about the hosts on Airbnb, they also downloaded all public profile pictures of the hosts in New York City and then still let workers on AMT to identity hosts' race.     

- In the stage of statistical analysis and model building, they sequentially controlled the variables in linear regression models in order to avoid the confounding effects caused by them.    

Finally they found from the regression results that non-black hosts charge approximately 12% more than black hosts for the equivalent rental.        

This study leverages two kinds of computational methods. The first is scraping observational data from the Internet for study and combining them with relevant existing information, including the dependent variable (price) and other control variables containing the information of quality and rating for apartments and hosts. It also takes advantage of human computation project through Amazon Mechanical Turk to rate the apartments in photos and to identify the races of the hosts in pictures. The ratings were used as control variable and the races were used as independent variable. Therefore, this study obtains the dependent variable, the independent variable and the control variables through computational methods.    


### Evaluation of Effectiveness      

This study has some good features of digital data. First, their data is **non-reactive** and thereby can improve the accuracy of evaluation. Racial discrimination is one of the most sensitive topics in contemporary United States. Many actual racists would disguise their identity if the have the time and the space to react. Besides, racial discrimination is structural. Many people will have unconscious racist behavior but do not realize them as long as they are not in a non-reactive situation. Therefore, the non-reactive data from Airbnb website in this study can avoid the error caused by respondents' reaction and evaluates people's behavior in the natural situation.      

Second, their research design (observational data and human computation project) can obtain a considerably **large-size and plentiful** information at **a very low cost of time, energy and money**. If we adopt traditional methods to study this topic, we have to visit these apartments one by one and also cannot obtain the information about rating for controlling variables.     

Third, although their original data is **dirty** (containing many pictures), the human computation project transformed the dirty form into the clean form (categorical variables). Finally, due to the **always-on** of the online data, their data can be longitudinal so that they can further enrich their data by time and then do a longitudinal analysis.        

However, there are still some drawbacks in their research design. First and most importantly, they should have put the variable "time" into their regression model. As we know, the demand and the supply in house rental marketplace are seasonal so that time has a very large influence on the price. As long as we don't know whether differently racial hosts have different time preferences of renting out their houses as well as of setting the price, the variable "time" should be put into the model. For example, if black are more likely to rent their houses in slack season than other races, the price gap is not necessarily derived from discrimination. Besides, the variable "time" can also reduce the influence from **user shift**. For example, assuming that in some time periods lots of black landlords start to use Airbnb and lead to an average lower price, we cannot correctly evaluate the real difference between black and non-black if we just use mixed data sets. Since the variable "time" usually (not always) reflects user shift, it is very important in regression model. In the same logic, the variable "time" can also partly reduce the impact derived from **algorithmic confounding**.

Second, it is very obvious that their data is **incomplete**. They wanted to obtain the complete data from Airbnb, but were denied by it since their study were very likely to have a negative impact on its economic interests. This fact makes the complete data **inaccessible**. Therefore, they can only use the incomplete information to build models. Without other very important variables, such as demand, supply and hosts' anticipatory prices race by race, their results become problematic even though they can use variable "time" to partly supplement the incompleteness. 

Third, as the biggest city in the United States, New York City **cannot represent** the majority of other cities. Therefore, it is not suitable to generalize to the racial discrimination in the whole online marketplace simply according to the data about NYC. Finally, this paper does not mention how they can evaluate the effectiveness of the ratings of apartment photos. Seven-point-scale (large-scale) ratings are full of uncertainty when they are done by lots of people.   


## The Second Paper    
### Research Design        

Using an experiment on Airbnb, the researchers in this paper explored racial discrimination against guests in house rental marketplace. Specifically, they evaluated the rental acceptance rate gap between black and non-black, and thereby evaluated the racial discrimination on Airbnb.      

- **Observational Data:** They first collected the data on all properties on Airbnb (similar to the first paper) in five metropolitan areas, the data about detailed host characteristics, their images and the information of reviews. After data collection, they hired workers on Amazon Mechanical Turk to identify race, gender and age according to host images and also used Face++, a face-detection API, to categorize past guests by age, race and gender according to reviews. Besides, they also linked census demographic data through the collected data and thereby assessed the relationship between neighborhood demographics and discrimination.     

- **Experiment:** They set four main treatment groups based on race and gender which were perceived by survey-validated names signaling black males, black females, white males and white females. The 20 identical Airbnb accounts except for guest names were divided into four groups with the sample size according to race and gender mentioned above. Identical messages except for data and name were sent to prospective hosts through these 20 accounts, and each account would only sent one message to one randomly selected host.  The rental date were the weekend that were eight weeks distance from the time of sending message. In addition, they also made sure that the hosts they selected had a room at that time. Finally around 6400 messages were sent to host between July, 25, 2015 and July 30, 2015. The researchers tracked host responses over 30 days and coded them into categories. Finally, they calculated the difference of replied acceptance rate between accounts with black and non-black names based on different subgroups divided by many control variables, and also computed the cost of host incurred by discrimination.     

The final findings are that guests with black names are 16% less likely to be accepted than non-black and this result is caused by the discrimination from a subset of hosts (those who never had an black guest). Besides, discrimination would incur a cost with the median between $60 and $100 revenue.     

This study takes advantage of several computational methods. The researchers scraped the observational data from Airbnb and coded them into categories through human computation project (AMT). Parts of them became control variables in  the experiment and another parts were used for designing the experiment (e.g. selecting target hosts in experiment). Besides,  the experiment is also digital because it was conducted directly on Airbnb. Finally, when researcher identified the demographic information in reviews they also used a face-detection API "Face++".


### Evaluation of Effectiveness       

As for the effectiveness observational data in this study, they should have shared similar characteristics with the first paper. However, since the observational data here is simply used to provide some necessary but basic information for the experiment, we only need to focus on a very small number of its features. First, the observational data is still as non-reactive as that in the first paper. Second, because they only need the basic demographic and/or contact information about hosts, the rental information and reviewing information, the observational data looks much more complete in terms of this objective. But unfortunately the researchers were blocked by Airbnb after they only scraped 5 cities. Therefore, the data is still incomplete and inaccessible. Finally, since the researchers wanted to compute the cost of discrimination, they have to know the empty rate caused by rejecting a guest of a disfavored race. In this case, the always-on characteristic provided them the opportunity to trace the empty rate. 

As for the experiment, the researchers adopted many methods to ensure their internal validity. First, they conducted a survey to make sure that the names they selected can accurately signal the correct racial and gender information. Second, when they manually coded pictures, they hired two workers to code the same one. If the codes from two workers were different, it would be identified by the third worker. If they still had no agreement, it would be coded as "unknown". This procedure grantees the accuracy of coding. Besides, they also discreetly designed the procedure of messaging, such as avoiding hosts who have several rental houses to receive multiple messages and ensuring the availability of rental house in the target weekend. All in all, the internal validity of their experiment is very strong. Besides, since this experiment was conducted in the natural setting and the hosts did not know they were studied, the external validity is also largely ensured. As for the construct validity, the researchers clearly transformed the abstract concept "racial discrimination" into the measurable variable: acceptance rate gap between black and non-black.    

Although this experiment has a strong valid, the heterogeneity of treatment effects is a problem for it. The biggest question is that they did not successfully scrape all 20 cities due the block from Airbnb. The result in this study may not fit in the situations of other cities since the ethos and population composition of different cities can be vastly different in the United States.    

Finally, I think that this study does not reveal any causal mechanism and even causal inference in the field of racial discrimination, or say, this study never aims to study causality. It does conclude that those who never had a black guest discriminate black by further dividing the main four group into subgroups according to other variables derived from observational data, but this is a circular argument. In the case that the researcher had beforehand assumed that acceptance rate gap is the representation of discrimination, they had assumed that discrimination is the causal inference of acceptance rate. Now the conclusion just in turn says those whose acceptance rate  for black is zero discriminate black. Therefore, in this study we knows nothing than the existence of discrimination and the correlation between acceptance rate and discrimination.      


## Conducting Both Research Projects        

It is worth noting that the second study does use both observational data and experiment. The combination of them provides the researchers some information that just one of them cannot bring. The most obvious finding in the combination is the empty rate caused by rejecting a guest of a disfavored race and thus the cost of discrimination. Specifically, the calculation of empty rate caused by rejecting a guest of a disfavored race and the cost of discrimination must be based on the dynamic price and house availability traced by always-on observational data and the acceptance condition found by experiment.     

Besides, observational data can definitely reduce the negative impact caused by heterogeneity of treatment effects. One of the characteristics of observational data is big and thereby much easier to estimate the composition of population. On the contrary, the sample size in experiment method is usually small and in many cases we do not know whether the sample in experiment can represent the population. Therefore, when we have observational data, we have two methods to calibrate the experiment. On one hand, we can select sample in experiment according to the observational data. For example, the demographic or socioeconomic composition of hosts can be first calculated and then the hosts can be divided into subgroups according some major features such as race, gender and age. The sample in the experiment can be randomly selected from the observational data. In this case, the result of experiment can better represent the population. On the other hand, we can also conduct an experiment first and then weigh the results in experiment to simulate the population.      

Additionally, the results in the models built though observational data could provide the information which variables should be paid more attention to. Although every experiment would control variables, but there are too much variables in social sciences so that no one can guarantee they know everything. When we obtain the results from the observational data, we can regard some variables shows significance in statistical model results as the major control or treatment variables.



## Digital Survey         

The biggest problem of survey in the field of discrimination evaluation is that you can not directly ask other people whether they discriminate black. First, due to the political environment, many people would not admit they are racist. Second, many people who do not regard themselves as racist would display some racist behavior and sensual attitude. The first problem leads to the second problem: traditional surveys are usually non-situational. In other words, if we want to identify the authentic discrimination, we must evaluate the respondents' response or activities in situations. These two problems are related to measurement errors. In addition, there is still another problem: how can I avoid representation error? I plan to overcome the first kind of error in research design and the last kind of error in analysis.    

I will design a game-like survey and publish it on Facebook. The name of this game-like survey is "the matching degree between you and your friends". Each question in the survey questionnaire are situational. In other words, every question will provide the respondents a description of an area and ask their willing of living there (5-scale-point). The conditions contain crime rate, racial composition, price, sex composition and so forth. What's more, before each respondent was asked this kind of questions, they will be required to provide their basic information of age, gender and race. The first kind of questions will be randomly assigned to each question situation. Each respondent needs to answer three questions in three situations. They can also invite their friends to answer the questionnaire. The software of this questionnaire will calculate the gap of two users' scores and transform it into matching degree. There is no doubt I will analyze the original data. In other words, I can build regression models between the willing score and other variables, especially variable of race. Besides, since I have their basic demographic information, I can give different groups different weights to simulate the real population in my target area. This digital survey avoids to directly ask people's attitudes instead of asking them in some situations, and also uses post-stratification to reduce measurement error. What's more, this method is very cheap.


