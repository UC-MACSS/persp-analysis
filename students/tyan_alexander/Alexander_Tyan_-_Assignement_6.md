The ethics of the Montana election experiment
---------------------------------------------

##### MACSS 30000 - Assignment 6

##### Alexander Tyan

##### 11/20/2017

*1. Assess this study using Salganik's four principles of ethical
research.*

*i. Respect for persons*

According to Salganik (2017), the principle has two parts: treating
individuals as autonomous and offering additional protections to
vulnerable persons. This is usually applied through presenting potential
study subjects with the informed consent form (i.e. “relevant
information in a comprehensible format”). The researchers have
implemented some approaches to ensure that the study respects the
subjects (potential voters), but have not done everything possible to
satisfy this principle.

It does not seem like the study considered any additional protections
for individuals with “diminished autonomy.” Though it may not be clear
who such persons may be in this study’s case, one could perhaps think of
those with mental disabilities that would hamper an individual to
understand the contents of the mailer (e.g. that this is a research
study). For instance, such individuals may be not able to seek further
information about the study through the website provided. Though perhaps
the study chose to ignore such protections as the information about such
vulnerable population groups may not have been readily available to
researchers.

In regards to treating individuals as autonomous through an informed
consent process, the study did not offer a formal consent form, instead
opting for a mailer. I presume the authors treated the mailer as a
proxy-informed consent form, since it provided information on further
study details, organizational affiliation and funding, etc (Richman
2015). The mailer did not disclose the full purpose of the study (i.e.
whether the information induces higher voter turnout), but this may have
been justified to avoid Hawthorne effects and desirability bias noise.
Additionally, the PIs have not allowed participants to opt out of the
experiment, since everyone in the mailing list received the “treatment”
(i.e. the information mailer) regardless of their wishes. However, this
may have not been any different from what a person may be exposed to
under usual living conditions, as unwanted mail is quite commonplace.

However, one major omission in respecting the persons is the intentional
use of the great seal of the state, which may have confused some
participants about the official endorsement of the study (despite
small-print text stating otherwise). If the study was not affiliated
with the government of Montana, respecting persons should have led the
researchers to avoid the use of the seal because this may have been and
was interpreted as misinformation. Furthermore, this may have been
illegal under local laws (see (iv)).

*ii. Beneficence* Beneficence is about maximizing possible benefits and
minimizing potential harm (Salganik 2017). This includes both the
participants and the social systems.

First, let us discuss potential harm. Regarding the participants, I do
not perceive any grave individual harm done because of the study, as the
subject matter did not involve any physical/bodily intervention or a
risk of significant emotional trauma. The worst-case scenario for a
participant was a higher chance of voting and, perhaps, voting for a
different candidate based on perceived ideological alignment. But that
would just be a more “informed” choice, since the ideological scoring by
the researchers was based on publically available funding information.
One way to criticize this aspect of the study is to presume that the
researchers assessment of the ideological scores was objectively
erroneous and/or misleading, though such an evaluation would require a
deeper methodological assessment outside of this assignment’s scope. One
other potential harm to a participant may have been being misinformed
about the role of the great seal used on the mailer (see (i)). Regarding
the social system, the study’s beneficence may at first seem more
ambiguous. This is because, in a more closely run race (which was not
the case), such intervention could be more controversial, since it could
have altered the “organic” state of the system in a tangible way, i.e.
swaying the results of an election. However, the fact that this race was
intentionally chosen for the low probability of a contested election
shows that the researchers attempted to minimize the risk of the
intervention harm to the social system they were studying.

Second, let us discuss potential benefits. In regards to participants,
the most tangible benefit, as mentioned, is a possibility of a
better-informed election choice. In regards to the social system, the
benefit is an overall higher turnout and, thus, better civic engagement
by the citizens. Another general benefit is a better scientific
understanding of how information may/should impact non-partisan races,
something that political scientists have not studied as closely as in
the case of partisan elections (Willis 2014). So, overall, it seems that
the study balances risks and benefits pretty well, especially
considering the importance of contributing to the knowledge of
non-partisan election dynamics.

*iii. Justice* Salganik (2017) talks about the fair distribution of
risks and benefits. The study did not treat all subjects equally in
treatment distribution (see \#3). But if we assume, for the moment, that
the sample was random, this would amount to attempting not to single out
one part of the population over others in distributing the risks and
benefits discussed under Beneficence. Under \#3, this assumption is
relaxed. Also, if there is a significant heterogeneity of treatment
effects between population groups, one could conceivably argue that the
distribution of risks/benefits is not fair to different parties. See \#2
for more discussion on this. iv. Respect for law and public interest

Salganik (2017) breaks down respect for law and public interest to
Compliance and Transparency-based Accountability. In terms of legal
compliance, the study’s use of the great seal of Montana and the mailer
contents were questionable, as determined by the Commissioner of
Political Practices of the State of Montana. In terms of
Transparency-based Accountability, this research was marred with the
controversy before the researchers had the chance to publish the results
for the discussion with the scientific community and the public. So, in
this sense, the PIs did not have the chance to go publicly transparent
with their research. However, they could have been in better
communication (i.e. more transparent) with the local campaign watchdog
authorities prior to even conducting the study. This could have
preempted the PR debacle that followed the study. Moreover, the
researchers did not submit the mailer with the seal to the IRB approval
at neither Stanford nor Dartmouth, which also seems not consistent with
the federally-regulated IRB practices (Salganik 2017).

Thus, the researchers have failed to not only respect the local law, but
also common IRB practices.

*2. Assume that the mailers were sent to a random sample of voters:
under what conditions might this mailing have altered the outcome of the
Supreme Court Justice election?* One possible condition for such a
scenario is if there is a substantially large heterogeneity of treatment
effects between different population groups, with say a group affiliated
with one party being more prone to mobilize to vote in response to
treatment than another group. For instance, say that receiving a mailer
with the ideological information in the study tends to not mobilize
Republican voters very much, but tends to encourage voting in Democrats
quite a bit, as compared to the system without the researchers’
experiment. If the treatment was randomized, the proportion of
Republican vs Democrat voters would be similar in the sample and the
general Montana population. But even though the treatment was
randomized, if this difference in effects between the two groups was
large enough (and/or that in the non-treatment world the race was
already close enough), the heterogeneity could potentially alter the
elections results. In this hypothetical scenario, the treatment would
favor a Democratic candidate, but one could imagine this mechanism
working in either direction. Additionally, this would be even more of a
risk if the sample was quite large, giving this effect an effectively
larger broadcast over the population. In fact, the sample was indeed
quite large, at about 15% of registered voters (Salganik 2017). In
conclusion, conditions that could alter a result would be significant
heterogeneity of treatment effects, already close-enough race, and a
large enough sample exposed to treatment.

*3. In fact, the mailers were not sent to a random sample of voters.
According to a report by Jeremy Johnson (a political scientist who
assisted in the investigation), mailers "were sent to 64,265 voters
identified as likely liberal to centrist leaning in Democratic leaning
precincts and 39,515 voters identified as conservative to centrist in
Republican leaning precincts. The researchers justified the disparity
between Democratic and Republican numbers on grounds that they
anticipated turnout to be significantly lower among Democratic voters."
Does this change your assessment of the research design? If so, how?*

Yes, as discussed in under \#1, (iii), researchers should consider
Justice as one of the ethical principles. Salganik (2017) argues that
when considering fair distribution of risks and benefits, researchers
are to think about not only the participants, but the systems more
generally. In this scenario, where researchers are intervening in a way
that is understandably designed to enhance the research results, they
are also consciously altering the organic state of the system in way
that potentially mobilizes Democrat voters more than Republican ones
because the Democrat sample is unrepresentatively larger than the
Republican sample. In such a scenario one could argue that the study
does not satisfy the Beneficence and Justice principles of ethical
research. Though, if one refers to \#2, we can see that either way,
doing random or not random sampling, may pose risks for altering the
system in a potentially politically controversial way. In other words,
there is no easy way to predict the future and foresee all risks.

*4. In response to the investigation, the researchers said that they
picked this election in part because "neither judicial race had been
closely contested in the primary. Based on an analysis of the 2014
primary election results in the context of previous Montana judicial
elections, the researchers determined that the research study as
designed would not change the outcome of either contest." Does this
change your assessment of the research? If so, how?* Generally, no,
because the principles that are important to consider in \#1, \#2, and
\#3 are still crucial to conducting an ethical study regardless of
anticipated results (forecasts can be wrong, after all). However, such a
defensive argument is a fallback for potentially controversial scenarios
in \#2 and \#3, so it gives the researchers a partial justification in
case these scenarios take place. However, this still does not resolve
other ethical issues, such as the ones in the legal and individual
respect realms with using an (misleading) official government seal.

*5. In fact, the election turned out to be not particularly close. Does
this change your assessment of the research? If so, how?* No, as
outlined in \#4, this justifies some of the shortcomings of the research
design in terms of ethics, but does not resolve all of the issues.

*6. One of the principal investigators for the Montana election study
(Adam Bonica) is also the co-founder of CrowdPAC, a for-profit company
which "calculates objective scores for political candidates showing
their overall political position" using, in part, the same data used to
score the judicial candidates in Montana. While a source of objective
information for voters to make decisions about candidates, CrowdPAC also
provides tools to organize activist communities and fund political
campaigns (all for a fee). Does this change your assessment of the
research? If so, how?* No, because my assessment is independent of how
such “objective” scoring mechanisms may be “weaponized” in other
contexts. Information or tools can be ethically neutral and their
ethical evaluation would depend on the context in which they are used.
In the context of the study, the information was used to advance general
knowledge about non-partisan elections, with all of the ethical
assessment above unrelated to how one may use this technology of
evaluating a candidate’s political ideology in other contexts. (Though
of course one could include the assessment of this scoring method’s
potential shortcomings in “objective” evaluation of political stance and
all of the resulting ethical considerations as well. See \#1, ii). For
instance, just because nuclear technology can be used to harm millions
does not have anyone advocating to ban the use of nuclear technology in
radiology medicine that benefits many patients. Similarly in this case,
to change my assessment at this point would be rationally and ethically
inconsistent.

*7. What, if anything, would you have done differently if you were the
principal investigators? How would you have designed the study if you
were interested in exploring whether additional information increases
voter turnout in nonpartisan races?* Based on the previous analysis,
several suggestions could be implemented. First, to improve the respect
for persons, on can implement a recruitment stage for this study, where
the participants are informed more formally and thoroughly of the
study’s risks and benefits and have a chance to sign an official
consent. This could be done without disclosing all of the study’s
intent, as letting participants know that the voter turnout is the
subject of interest may introduce desirability bias into their behavior.
Such recruitment procedure can also be used as a screening mechanism to
more formally identify vulnerable population groups to exclude them from
the study or apply additional protection measures. Identifying
vulnerable groups is something that the study did not seem to consider.
However, one would have to consider potential additional costs to
implement this proposed research stage, as it may put the total study
costs out of the budget’s reach.

Second, of course a more rigorous IRB procedure would need to be
followed. How did this study see the light of day when the mailer, the
main subject of controversy, was never approved by the IRB? It is a
mystery and shows that much is to be improved in terms of researchers
having more disciplined integrity to follow the IRB procedures.

Third, one commonplace mistake for researchers getting into PR debacles
seems to be a lack of contextual and situational awareness. In this
case, it seemed to be a lack of knowledge of local legal intricacies in
conducting political campaigns and a general lack of anticipation of how
Public Relations work. Thus, one modification would be to consider
additional legal and PR advice. It may be hard to know what these
intricacies may be across many jurisdictions, but this study seems
localized enough that the researchers could have given this greater
consideration. It is no wonder that Dartmouth intended to add a legal
adviser to their IRB board after this incident (Richman 2015). This
practice should become common place, along with PR advising in studies
that merit such preparation and this such prior consultation would be
one change I would implement.

Bibliography

Richman, Josh. 2015. “Stanford and Dartmouth Researchers Broke Law with
Election Mailer, Montana Official Says.” The Mercury News (blog). May
12, 2015.
<http://www.mercurynews.com/2015/05/12/stanford-and-dartmouth-researchers-broke-law-with-election-mailer-montana-official-says/>.

Salganik, Matthew J. 2017. Bit by Bit: Social Research in the Digital
Age. Princeton, NJ: Princeton University Press.

Willis, Derek. 2014. “Professors’ Research Project Stirs Political
Outrage in Montana.” The New York Times, October 28, 2014, sec. The
Upshot.
<https://www.nytimes.com/2014/10/29/upshot/professors-research-project-stirs-political-outrage-in-montana.html>.
